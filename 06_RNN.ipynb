{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde05991-8ab7-4d99-b191-308d82f88fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1cbd7b-0e4d-47c9-816e-f1a4bb179020",
   "metadata": {
    "colab_type": "text",
    "id": "odrahCJWiHVf"
   },
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "## Layers\n",
    "\n",
    "### RNN Layer\n",
    "\n",
    "[`nn.RNN`](https://pytorch.org/docs/stable/nn.html#rnn) 합성곱 연산층은 다음과 같은 arguments를 받는다.\n",
    "\n",
    "* `input_size`: 입력 토큰의 차원수\n",
    "* `hidden_size`: 히든 뉴런 갯수\n",
    "* `num_layers`: 층의 갯수\n",
    "* `nonlinearity`: 활성화 함수, 기본으로 tanh 로 설정되어있다.\n",
    "* `batch_first`: 미니배치 차원이 제일 앞에 있는지 여부를 체크, 기본 형태가 (T, B, input_size) 로 되어 있다. 활성화 하면 (B, T, input_size)로 입력을 넣어줘야한다.\n",
    "* `bidirectional`: 양방향 RNN 활성화 여부\n",
    "\n",
    "**single layer rnn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b21822-e6d6-4ddd-9d33-72f414bda9d9",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJFk0mPfiHVg"
   },
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 20\n",
    "rnn_layer = nn.RNN(input_size=input_size, \n",
    "                   hidden_size=hidden_size, \n",
    "                   batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e27bd9-370f-41d5-883c-f50aea5c0421",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1575966826045,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "_onJDqwFz5DZ",
    "outputId": "11444a11-6466-4d36-8e00-57bb2dfd3a86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer.weight_ih_l0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a504823-6cc3-4038-a922-ec9531f46d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 5\n",
    "time_step = 4\n",
    "inputs = torch.rand(batch, time_step, input_size)\n",
    "hiddens = torch.zeros(1, batch, hidden_size)\n",
    "outputs, hiddens = rnn_layer(inputs, hiddens)\n",
    "\n",
    "# inputs: (B, T, I)\n",
    "# outputs: (B, T, H)\n",
    "# hiddens: (num_layer, B, H)\n",
    "\n",
    "print(f\"outputs: {outputs.size()}\\nhiddens: {hiddens.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11489ac8-e85c-46bf-aaa0-94f9e3fa99b7",
   "metadata": {
    "colab_type": "text",
    "id": "CXi7aur9iHVo"
   },
   "source": [
    "**multi-layer rnn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed73d0-2527-43fb-9d37-9669a5ac3f55",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPd2XzL0iHVp"
   },
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "rnn_layer = nn.RNN(input_size=input_size, \n",
    "                   hidden_size=hidden_size, \n",
    "                   num_layers=num_layers,\n",
    "                   batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2638bd-1c66-4add-babd-57bbbcfbe120",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1001,
     "status": "ok",
     "timestamp": 1575966838103,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "jApvP22ziHVr",
    "outputId": "d85452ec-0e32-45cc-a0d6-005defb236bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: torch.Size([5, 4, 20])\n",
      "hiddens: torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(batch, time_step, input_size)\n",
    "outputs, hiddens = rnn_layer(inputs)\n",
    "\n",
    "# inputs: (B, T, I)\n",
    "# outputs: (B, T, H)\n",
    "# hiddens: (num_layer, B, H)\n",
    "\n",
    "print(f\"outputs: {outputs.size()}\\nhiddens: {hiddens.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2127e72-2dc3-4b2e-91ae-961a0e6fe9cd",
   "metadata": {
    "colab_type": "text",
    "id": "n4P8eMTFiHVt"
   },
   "source": [
    "**bidirectional rnn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3654e41-59f7-432b-b139-9f63144df599",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuLdxwUUiHVt"
   },
   "outputs": [],
   "source": [
    "bidirection = True\n",
    "rnn_layer = nn.RNN(input_size=input_size, \n",
    "                   hidden_size=hidden_size, \n",
    "                   num_layers=num_layers,\n",
    "                   batch_first=True,\n",
    "                   bidirectional=bidirection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b55bfc-6a57-41a6-a432-4f823de59930",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1575966840812,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "PJTeW1q8iHVv",
    "outputId": "84b88450-511a-40ff-9fb7-769bc8186110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: torch.Size([5, 4, 40])\n",
      "hiddens: torch.Size([4, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(batch, time_step, input_size)\n",
    "outputs, hiddens = rnn_layer(inputs)\n",
    "\n",
    "# inputs: (B, T, I)\n",
    "# outputs: (B, T, H*2)\n",
    "# hiddens: (num_layer*2, B, H)\n",
    "\n",
    "print(f\"outputs: {outputs.size()}\\nhiddens: {hiddens.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30c86f-49a3-4872-8e91-37414fe0bb68",
   "metadata": {
    "colab_type": "text",
    "id": "jsgsxOTRiHVw"
   },
   "source": [
    "### LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c011b99-c20d-4773-9863-777efd14d5a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1575966842445,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "iKYuqsk6iHVx",
    "outputId": "0eb903d9-0754-4cd9-da3c-ecbed6120f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: torch.Size([5, 4, 20])\n",
      "hiddens: torch.Size([2, 5, 20])\n",
      "cells: torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "lstm_layer = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "hiddens = torch.zeros(num_layers, batch, hidden_size)\n",
    "cells = torch.zeros(num_layers, batch, hidden_size)\n",
    "\n",
    "outputs, (hiddens, cells) = lstm_layer(inputs, (hiddens, cells))\n",
    "\n",
    "# inputs: (B, T, I)\n",
    "# outputs: (B, T, H)\n",
    "# hiddens: (num_layer, B, H)\n",
    "# cells: (num_layer, B, H)\n",
    "\n",
    "print(f\"outputs: {outputs.size()}\\nhiddens: {hiddens.size()}\\ncells: {cells.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62f74a-e4e8-4c4d-8d55-e827ef205a90",
   "metadata": {
    "colab_type": "text",
    "id": "nVDmRRxyiHVy"
   },
   "source": [
    "### GRU Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77442982-6d89-4af5-b8d7-55881ae34ea5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1575966844466,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "Kzd2jM9_iHVz",
    "outputId": "e8de5491-4e21-4b1d-c2eb-7be178e82580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: torch.Size([5, 4, 20])\n",
      "hiddens: torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "gru_layer = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "hiddens = torch.zeros(num_layers, batch, hidden_size)\n",
    "\n",
    "outputs, hiddens = gru_layer(inputs, hiddens)\n",
    "\n",
    "# inputs: (B, T, I)\n",
    "# outputs: (B, T, H)\n",
    "# hiddens: (num_layer, B, H)\n",
    "\n",
    "print(f\"outputs: {outputs.size()}\\nhiddens: {hiddens.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b2144-76f7-45b5-bab9-4fca78fcad2c",
   "metadata": {
    "colab_type": "text",
    "id": "wm2OjWnSiHV0"
   },
   "source": [
    "---\n",
    "\n",
    "# 이름 분류기 만들기\n",
    "\n",
    "RNN을 사용해 5개의 국가(\"German\", \"United States\", \"Spain\", \"Korean\", \"Russian\" )의 이름 데이터를  입력하면 어떤 국가의 이름인지 분류하는 모델 만들기\n",
    "\n",
    "## Sequential Data Processing\n",
    "\n",
    "1. 이름을 한 글자씩 분해한다.\n",
    "2. pad, unknown을 포함해서 사용된 모든 문자에 각각 유니크한 숫자를 부여한다.\n",
    "3. 각 배치에 알맞게 길이가 맞지 않는 데이터를 동일하게 만들기 위해 \"\\<pad\\>\" 데이터를 붙인다. \n",
    "\n",
    "\n",
    "* `<unk>`: 알지 못하는 문자에 대처\n",
    "* `<pad>`: 배치 데이터 길이를 맞추기 위함\n",
    "\n",
    "```\n",
    "15: \n",
    "'D', 'i', 'e', 't', 'h', 'a', 'r', 'd', ' ', 'T', 'e', 'x', 't', 'o', 'r'\n",
    "\n",
    "11 + 4: \n",
    "'M', 'a', 'r', 'c', 'o', ' ', 'D', 'i', 'e', 't', 'z', '<pad>', '<pad>', '<pad>', '<pad>'\n",
    "...\n",
    "```\n",
    "\n",
    "### Custom Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2743c-d3ca-4ff9-a3b4-a27079cc25c0",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Suro5ulCiHV1"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path, fmt=\"\\t\", pad_idx=1, vocab_stoi=None, labels_stoi=None):\n",
    "        # 파일에서 데이터를 불러오고 전처리 등을 진행\n",
    "        with Path(path).open(mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            datas = file.readlines()\n",
    "        datas = [line.strip().split(fmt) for line in datas]\n",
    "        datas, labels = list(zip(*datas))\n",
    "        datas = [list(d) for d in datas]\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        if (vocab_stoi is None) and (labels_stoi is None):\n",
    "            self.vocab_stoi = defaultdict()           # dictionary 확장값. 값이 없어도 에러 안남\n",
    "            self.vocab_stoi[\"<unk>\"] = 0\n",
    "            self.vocab_stoi[\"<pad>\"] = self.pad_idx   # 1이들어감\n",
    "        \n",
    "            self.labels_stoi = defaultdict()  \n",
    "            labels_unique = set(labels)\n",
    "            for i, label in enumerate(labels_unique):\n",
    "                self.labels_stoi[label] = i\n",
    "        else:\n",
    "            self.vocab_stoi = vocab_stoi\n",
    "            self.labels_stoi = labels_stoi\n",
    "        \n",
    "        for name in datas:\n",
    "            for letter in name:\n",
    "                if self.vocab_stoi.get(letter) is None:\n",
    "                    self.vocab_stoi[letter] = len(self.vocab_stoi)\n",
    "        self.vocab_len = len(self.vocab_stoi)\n",
    "        self.vector_matrix = torch.eye(self.vocab_len)\n",
    "        \n",
    "        self.datas = datas\n",
    "        self.labels = labels\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # 인덱스에 해당하는 데이터셋 리턴\n",
    "        return self.datas[index], self.labels[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # 데이터셋 수\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def custom_collate_fn(self, data):\n",
    "        x, y = list(zip(*data))\n",
    "        max_len = max([len(name) for name in x])\n",
    "        datas = [list(map(self.vocab_stoi.get, name)) for name in x]\n",
    "        datas = [name + [self.pad_idx]*(max_len - len(name)) if len(name) < max_len else name for name in datas]\n",
    "        datas = torch.stack([torch.stack(list(self.vector_matrix[idx] for idx in name)) for name in datas])\n",
    "        labels = list(map(self.labels_stoi.get, y))\n",
    "        \n",
    "        return datas, torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c21c3f-ef49-4437-9f0c-8bc9ab58615d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2xWcseWEiHV2"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_txt = \"names/names_{}.tsv\"\n",
    "batch_size = 64\n",
    "train_dataset = CustomDataset(path_txt.format(\"train\"), fmt=\"\\t\")\n",
    "test_dataset = CustomDataset(path_txt.format(\"test\"), fmt=\"\\t\", \n",
    "                             vocab_stoi=train_dataset.vocab_stoi,\n",
    "                             labels_stoi=train_dataset.labels_stoi)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          collate_fn=train_dataset.custom_collate_fn,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         collate_fn=test_dataset.custom_collate_fn,\n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702df2e-6e8b-4b1d-a304-f5e0c799ba6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1575966850226,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "iVzQYDAOiHV3",
    "outputId": "6ddf57c7-a969-4ea9-d5d2-605233832161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 41, 222]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for names, labels in train_loader:\n",
    "    break\n",
    "print(names.size(), labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426b1fe-91dd-443e-8a3c-171657c1211f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1575966852918,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "vaOTWAle6RKf",
    "outputId": "d661c6d5-6ddd-41b6-a21a-ceb2227b81a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809fae5-3246-4197-bfec-241798a7e97d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1575966854606,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "vv_BG5WV6lDD",
    "outputId": "3c8ec34c-fdc9-4ccc-dc91-5ca8bbc42579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(131)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0][0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06524177-43fd-49ea-9616-7c710eabd685",
   "metadata": {
    "colab_type": "text",
    "id": "MPSjdsofiHV5"
   },
   "source": [
    "## RNN 모델\n",
    "\n",
    "### 네트워크 설계\n",
    "\n",
    "* Input Size = (B, T, vocab_size)\n",
    "* Output Size = (B, 5)\n",
    "* Loss Function(`nn.CrossEntropyLoss`): Cross Entropy Loss\n",
    "* Optimizer(`optim.Adam`): Adam\n",
    "* RNN Layer: `nn.LSTM`을 사용해서 `self.lstm_layer` 변수에 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d78a3f-dfe8-4906-986a-ab12fbec3eaa",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gvwj6YYXiHV5"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(Network, self).__init__()\n",
    "        # 층을 구성\n",
    "        self.lstm_layer = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # forward propagation 수행\n",
    "        outputs, (hiddens, cells) = self.lstm_layer(x)\n",
    "        # x: (B, T, I)\n",
    "        # outputs: (B, T, H)\n",
    "        # hiddens: (num_layer, B, H)\n",
    "        # cells: (num_layer, B, H)\n",
    "        last_hidden = hiddens[-1]  # (B, H)\n",
    "        o = self.linear(last_hidden)\n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b3595-cd45-48f3-aeda-eccb5ed41d17",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USlPRNO7iHV7"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "input_size = len(train_dataset.vocab_stoi)\n",
    "hidden_size = 200\n",
    "output_size = len(train_dataset.labels_stoi)\n",
    "num_layers = 3\n",
    "# 커스텀 모듈 호출\n",
    "model = Network(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "# loss_function = \n",
    "# optimizer = \n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba89eab-f7e8-4ab1-8b1b-2c2e23709e63",
   "metadata": {
    "colab_type": "text",
    "id": "R4UiNmOHiHV8"
   },
   "source": [
    "## 모델훈련\n",
    "\n",
    "### Train 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29214984-df79-42ad-89ab-ac24c49b2ff5",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoUiL8DDiHV9"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_function, optimizer, n_train, print_step, device):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 경사 초기화\n",
    "        model.zero_grad()\n",
    "        # 순방향 전파\n",
    "        output = model(data)\n",
    "        # 손실값 계산\n",
    "        loss = loss_function(output, target)\n",
    "        # 역방향 전파\n",
    "        loss.backward()\n",
    "        # 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "        # 중간 과정 print\n",
    "        if batch_idx % print_step == 0:\n",
    "            percentage = (batch_idx*train_loader.batch_size / n_train) * 100\n",
    "            print(f\" - [{percentage:.2f}%] train loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0ccd89-3697-4695-b80d-1bf8f6318181",
   "metadata": {
    "colab_type": "text",
    "id": "noKRx6r2iHV-"
   },
   "source": [
    "### Validation 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b3f89-2c96-45a6-a10c-1744fc350d60",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iB-2wud7iHV_"
   },
   "outputs": [],
   "source": [
    "def validation(model, test_loader, loss_function, n_test, device):\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # torch.no_grad 를 사용하면 requires_grad 를 꺼두게 된다.\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 순방향전파\n",
    "            output = model(data)\n",
    "            # 손실값 계산\n",
    "            test_loss += loss_function(output, target).item()\n",
    "            # 예측 값에 해당하는 클래스 번호 반환\n",
    "            pred = output.softmax(1).argmax(dim=1, keepdim=True)\n",
    "            # 정확하게 예측한 개수를 기록한다\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_accuracy = correct / n_test\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c7733-4c9d-4e02-a185-efdda9c4e2db",
   "metadata": {
    "colab_type": "text",
    "id": "8Li-Xba-iHWA"
   },
   "source": [
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da473879-39a1-4dac-8df7-9af4643bc590",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114195,
     "status": "ok",
     "timestamp": 1575966985725,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "ISKZrdFRiHWB",
    "outputId": "ab1c3d7d-345a-408d-936c-8a342373a9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step] 1/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 1.6023\n",
      " - [38.40%] train loss: 0.6040\n",
      " - [76.80%] train loss: 0.5116\n",
      " [Validation Step]\n",
      " - test loss: 3.6281 test accuracy: 63.80 %\n",
      "[Step] 2/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.6085\n",
      " - [38.40%] train loss: 0.3668\n",
      " - [76.80%] train loss: 0.3733\n",
      " [Validation Step]\n",
      " - test loss: 2.2209 test accuracy: 70.60 %\n",
      "[Step] 3/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.2361\n",
      " - [38.40%] train loss: 0.1283\n",
      " - [76.80%] train loss: 0.2790\n",
      " [Validation Step]\n",
      " - test loss: 2.1050 test accuracy: 71.80 %\n",
      "[Step] 4/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.2194\n",
      " - [38.40%] train loss: 0.1288\n",
      " - [76.80%] train loss: 0.1697\n",
      " [Validation Step]\n",
      " - test loss: 1.2318 test accuracy: 74.60 %\n",
      "[Step] 5/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.0788\n",
      " - [38.40%] train loss: 0.2678\n",
      " - [76.80%] train loss: 0.0864\n",
      " [Validation Step]\n",
      " - test loss: 1.3280 test accuracy: 74.20 %\n",
      "[Step] 6/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.1341\n",
      " - [38.40%] train loss: 0.1100\n",
      " - [76.80%] train loss: 0.0672\n",
      " [Validation Step]\n",
      " - test loss: 0.8637 test accuracy: 76.40 %\n",
      "[Step] 7/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.0318\n",
      " - [38.40%] train loss: 0.0344\n",
      " - [76.80%] train loss: 0.0254\n",
      " [Validation Step]\n",
      " - test loss: 1.0307 test accuracy: 76.00 %\n",
      "[Step] 8/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.1197\n",
      " - [38.40%] train loss: 0.0319\n",
      " - [76.80%] train loss: 0.0862\n",
      " [Validation Step]\n",
      " - test loss: 0.7001 test accuracy: 77.00 %\n",
      "[Step] 9/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.0882\n",
      " - [38.40%] train loss: 0.0026\n",
      " - [76.80%] train loss: 0.1233\n",
      " [Validation Step]\n",
      " - test loss: 0.5812 test accuracy: 77.60 %\n",
      "[Step] 10/10\n",
      " [Training Step]\n",
      " - [0.00%] train loss: 0.0469\n",
      " - [38.40%] train loss: 0.0158\n",
      " - [76.80%] train loss: 0.0311\n",
      " [Validation Step]\n",
      " - test loss: 0.8583 test accuracy: 76.20 %\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_dataset)\n",
    "n_test = len(test_dataset)\n",
    "n_step = 10\n",
    "print_step = 300\n",
    "best_accuracy = 0\n",
    "\n",
    "for step in range(n_step):\n",
    "    print(f\"[Step] {step+1}/{n_step}\\n [Training Step]\")\n",
    "    train(model, train_loader, loss_function, optimizer, n_train, print_step, device)\n",
    "    test_loss, test_accuracy = validation(model, test_loader, loss_function, n_test, device)\n",
    "    print(f\" [Validation Step]\")\n",
    "    print(f\" - test loss: {test_loss:.4f} test accuracy: {test_accuracy*100:.2f} %\")\n",
    "    # 제일 성능을 보인 좋은 모델 저장하기\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model-namecls.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e168f-5ff4-4bd2-a641-1daba2ca4e9d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgk6TBjGiHWD"
   },
   "outputs": [],
   "source": [
    "model = Network(input_size, hidden_size, output_size, num_layers)\n",
    "model.load_state_dict(torch.load(\"best_model-namecls.pt\", map_location=\"cpu\"))\n",
    "classes = {v: k for k, v in train_dataset.labels_stoi.items()}\n",
    "vocab = train_dataset.vocab_stoi\n",
    "\n",
    "def preprocessing(text, vocab):\n",
    "    temp = []\n",
    "    for x in list(text):\n",
    "        if vocab.get(x) is None:\n",
    "            temp.append(vocab[\"<unk>\"])\n",
    "        else:\n",
    "            temp.append(vocab[x])\n",
    "\n",
    "    idx = torch.LongTensor(temp)\n",
    "    input_tensor = torch.zeros(len(idx), len(vocab)).scatter(1, idx.unsqueeze(1), 1)\n",
    "    return input_tensor.unsqueeze(0)\n",
    "    \n",
    "def predict(model, vocab, classes):\n",
    "    model.eval()\n",
    "    text = input(\"이름을 입력: \")\n",
    "    input_tensor = preprocessing(text, vocab)\n",
    "    o = model(input_tensor).detach()\n",
    "    pred = classes.get(o.argmax(1).item())\n",
    "    probs = o.softmax(1).squeeze(0).numpy()\n",
    "    probs_dict = {label: p for label, p in zip(classes.values(), probs)}\n",
    "    print(f\"예측: {pred}\\nProbabilities: \")\n",
    "    for k, v in probs_dict.items():\n",
    "        print(f\"{k} = {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d8e76-c90b-4ebc-9fbe-62cfafbabf48",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zv7I-FF_91Yf"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "text = \"장지수\"\n",
    "input_tensor = preprocessing(text, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767487b-c15c-4b5b-96a5-4b7fc3b48b84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1575967444037,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "h0wu48Qy-Etf",
    "outputId": "bcc96b7a-40c5-4bfa-e49c-854c8612231f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get(\"현\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a2863-394d-4de1-857b-d428684a3c94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8122,
     "status": "ok",
     "timestamp": 1575967476983,
     "user": {
      "displayName": "ROCK HYUN CHOI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB5wtT-fIEWz-aT0bAUPpYscyKfrk-Osqn-JKHu=s64",
      "userId": "14080414791584977144"
     },
     "user_tz": -540
    },
    "id": "Z-EUgnqOiHWG",
    "outputId": "89afb551-ecc8-40ce-f10d-d96ecadfcaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이름을 입력: 최락현\n",
      "예측: Korean\n",
      "Probabilities: \n",
      "Korean = 0.8934\n",
      "Russian = 0.0023\n",
      "German = 0.0321\n",
      "United States = 0.0697\n",
      "Spain = 0.0025\n"
     ]
    }
   ],
   "source": [
    "predict(model, vocab, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
